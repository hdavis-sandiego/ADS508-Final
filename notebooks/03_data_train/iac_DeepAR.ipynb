{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4fe966-6e9d-4c11-ab39-0e2efdfbdf1c",
   "metadata": {},
   "source": [
    "# DeepAR Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2746d846-6958-47cc-9cdc-98d53e19e6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)\n",
    "\n",
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a674df7-1f48-4ab9-beba-26ac5a8046ad",
   "metadata": {},
   "source": [
    "## Get train/test dataframes from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330cea04-2dc6-4d34-9797-edf913ff67c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aurelia-resort-data/model_train/data_csv/test.csv to data/test.csv\n",
      "download: s3://aurelia-resort-data/model_train/data_csv/train.csv to data/train.csv\n",
      "download: s3://aurelia-resort-data/model_train/data_csv/test_nans.csv to data/test_nans.csv\n",
      "download: s3://aurelia-resort-data/model_train/data_csv/train_nans.csv to data/train_nans.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://aurelia-resort-data/model_train/data_csv ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c00183d-7d97-4e5a-b027-9a2f3bbb3f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_nans.csv\")\n",
    "test = pd.read_csv(\"data/test_nans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d7e653-a459-4de0-8481-5ffde68c1cff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4268f5435065411887f13fa7c320de0e"
      },
      "text/plain": [
       "          Date  num_stays  TotalAirlineTripstoDC  TotalAirlinePassengerstoDC  \\\n",
       "152 2022-02-01       4413                  415.0                   1069976.0   \n",
       "153 2022-03-01       7754                  448.0                   1529721.0   \n",
       "154 2022-04-01       9208                  429.0                   1636140.0   \n",
       "155 2022-05-01      10146                  451.0                   1707995.0   \n",
       "156 2022-06-01       8271                  469.0                   1649175.0   \n",
       "\n",
       "     TotalAmericanTravelers  PercentofAmericanswhoTraveled  \\\n",
       "152            7.730094e+08                      82.098828   \n",
       "153            7.760894e+08                      81.843971   \n",
       "154            7.760883e+08                      81.854948   \n",
       "155            7.778265e+08                      82.010600   \n",
       "156            7.739908e+08                      81.766838   \n",
       "\n",
       "     TotalTripsbyAmericans  income_total  \n",
       "152           3.757569e+09       15125.6  \n",
       "153           3.843540e+09       15064.1  \n",
       "154           3.993425e+09       15055.2  \n",
       "155           4.021791e+09       15036.4  \n",
       "156           3.830852e+09       14973.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a7eabc-5e17-4cb5-908e-76d8f86d3472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8101c4c139c419bae72880552edffad"
      },
      "text/plain": [
       "        Date  num_stays  TotalAirlineTripstoDC  TotalAirlinePassengerstoDC  \\\n",
       "0 2022-07-01       8002                    NaN                         NaN   \n",
       "1 2022-08-01       7866                    NaN                         NaN   \n",
       "2 2022-09-01       8091                    NaN                         NaN   \n",
       "3 2022-10-01       9588                    NaN                         NaN   \n",
       "4 2022-11-01       6964                    NaN                         NaN   \n",
       "\n",
       "   TotalAmericanTravelers  PercentofAmericanswhoTraveled  \\\n",
       "0                     NaN                            NaN   \n",
       "1                     NaN                            NaN   \n",
       "2                     NaN                            NaN   \n",
       "3                     NaN                            NaN   \n",
       "4                     NaN                            NaN   \n",
       "\n",
       "   TotalTripsbyAmericans  income_total  \n",
       "0                    NaN       15100.2  \n",
       "1                    NaN       15149.6  \n",
       "2                    NaN       15172.2  \n",
       "3                    NaN       15274.2  \n",
       "4                    NaN       15332.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0878249-b122-4ec5-a0b2-a5a62dc46278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638edf21-c04c-475e-baae-bc07529ced22",
   "metadata": {},
   "source": [
    "## Create JSON Object for DeepAR Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca236fd-ef30-4b1e-aea7-9ebc149a0b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Create JSON object by grouping train set by Date\n",
    "train_json = []\n",
    "for Date, group in train.groupby('Date'):\n",
    "    item = {\n",
    "        'start': Date.isoformat(),\n",
    "        'target': group[['TotalAirlineTripstoDC', 'TotalAirlinePassengerstoDC', 'TotalAmericanTravelers', 'PercentofAmericanswhoTraveled', 'TotalTripsbyAmericans', 'num_stays', 'income_total']].values.tolist()\n",
    "        #'dynamic_feat': group.drop(['Date', 'TotalAirlineTripstoDC', 'TotalAirlinePassengerstoDC', 'TotalAmericanTravelers', 'PercentofAmericanswhoTraveled', 'TotalTripsbyAmericans', 'num_stays', 'income_total'], axis=1).values.tolist()\n",
    "    }\n",
    "    train_json.append(item)\n",
    "    \n",
    "    \n",
    "# Create JSON object by grouping test set by Date\n",
    "test_json = []\n",
    "for Date, group in test.groupby('Date'):\n",
    "    item = {\n",
    "        'start': Date.isoformat(),\n",
    "        'target': group[['TotalAirlineTripstoDC', 'TotalAirlinePassengerstoDC', 'TotalAmericanTravelers', 'PercentofAmericanswhoTraveled', 'TotalTripsbyAmericans', 'num_stays', 'income_total']].values.tolist()\n",
    "        #'dynamic_feat': group.drop(['Date', 'TotalAirlineTripstoDC', 'TotalAirlinePassengerstoDC', 'TotalAmericanTravelers', 'PercentofAmericanswhoTraveled', 'TotalTripsbyAmericans', 'num_stays', 'income_total'], axis=1).values.tolist()\n",
    "    }\n",
    "    test_json.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ae764a-2f73-43ab-ac7c-7b2c42fd940d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_json))\n",
    "print(len(test_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82079fce-7ca2-46d9-934c-65dbaf4de574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '2009-06-01T00:00:00',\n",
       " 'target': [[nan, nan, nan, nan, nan, 2.0, nan]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d837211-3138-4320-837b-7c0531debb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed74802-3ee6-4401-acef-f281ae892b43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.2 ms, sys: 0 ns, total: 3.2 ms\n",
      "Wall time: 39.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"train.json\", train_json)\n",
    "write_dicts_to_file(\"test.json\", test_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dea786-11a1-47b4-afa8-4b57e485bf93",
   "metadata": {},
   "source": [
    "## Train Model with DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d07671-c117-4aa9-8338-0ac11db3b23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_data_path = \"s3://aurelia-resort-data/model_train/deepAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dcbbb07-07f3-429f-85c5-4cd989dbeb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    base_job_name=\"deepar-hotel\",\n",
    "    output_path=\"s3://aurelia-resort-data/model_train/deepAR/output/\",\n",
    "    hyperparameters={\n",
    "        \"time_freq\": \"M\",\n",
    "        \"prediction_length\": \"5\",\n",
    "        \"context_length\": \"2\",\n",
    "        \"num_cells\": \"40\",\n",
    "        \"num_layers\": \"2\",\n",
    "        \"likelihood\": \"student-t\",\n",
    "        \"epochs\": \"100\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d412843-49ea-4c1a-99c6-cc95be15731f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-09 19:07:47 Starting - Starting the training job...\n",
      "2023-04-09 19:08:14 Starting - Preparing the instances for training......\n",
      "2023-04-09 19:09:18 Downloading - Downloading input data...\n",
      "2023-04-09 19:09:38 Training - Downloading the training image.........\n",
      "2023-04-09 19:11:08 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:78: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '2', 'epochs': '100', 'likelihood': 'student-t', 'num_cells': '40', 'num_layers': '2', 'prediction_length': '5', 'time_freq': 'M'}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '2', 'epochs': '100', 'prediction_length': '5', 'time_freq': 'M'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] random_seed is None\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Real time series\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] number of time series: 48\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] number of observations: 336\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] mean target length: 7.0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] min/mean/max target: 0.0/467538660.1925572/4428887040.0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] mean abs(target): 467538660.1925572\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] contains missing values: yes (17.9%)\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Small number of time series. Doing 27 passes over dataset with prob 0.9876543209876544 per epoch.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Real time series\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] number of time series: 6\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] number of observations: 42\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] mean target length: 7.0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] min/mean/max target: 81.76683807373047/665649468.9523809/4021791232.0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] mean abs(target): 665649468.9523809\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] #memory_usage::<batchbuffer> = 0.25390625 mb\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] nvidia-smi: took 0.029 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067478.4238088, \"EndTime\": 1681067478.4525824, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 27.605533599853516, \"count\": 1, \"min\": 27.605533599853516, \"max\": 27.605533599853516}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] #memory_usage::<model> = 5 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067478.4526527, \"EndTime\": 1681067478.480749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 56.85544013977051, \"count\": 1, \"min\": 56.85544013977051, \"max\": 56.85544013977051}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Epoch[0] Batch[0] avg_epoch_loss=18.152538\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=18.152538299560547\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Epoch[0] Batch[5] avg_epoch_loss=16.725685\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=16.725685119628906\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Epoch[0] Batch [5]#011Speed: 7399.62 samples/sec#011loss=16.725685\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Epoch[0] Batch[10] avg_epoch_loss=16.781646\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=16.848799324035646\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:18 INFO 139724334417728] Epoch[0] Batch [10]#011Speed: 3640.90 samples/sec#011loss=16.848799\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] processed a total of 1907 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067478.4808087, \"EndTime\": 1681067479.0298903, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 100.0, \"count\": 1, \"min\": 100, \"max\": 100}, \"update.time\": {\"sum\": 548.9821434020996, \"count\": 1, \"min\": 548.9821434020996, \"max\": 548.9821434020996}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3472.502403193897 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=0, train loss <loss>=16.80845527648926\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[1] Batch[0] avg_epoch_loss=17.083504\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=17.08350372314453\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[1] Batch[5] avg_epoch_loss=16.090842\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=16.09084177017212\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[1] Batch [5]#011Speed: 6760.93 samples/sec#011loss=16.090842\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[1] Batch[10] avg_epoch_loss=15.998764\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=15.888270950317382\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[1] Batch [10]#011Speed: 3577.90 samples/sec#011loss=15.888271\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] processed a total of 1918 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067479.0300372, \"EndTime\": 1681067479.5835187, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 552.767276763916, \"count\": 1, \"min\": 552.767276763916, \"max\": 552.767276763916}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3467.741618890795 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=1, train loss <loss>=16.024405733744302\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[2] Batch[0] avg_epoch_loss=15.339320\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=15.339320182800293\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[2] Batch[5] avg_epoch_loss=15.621742\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=15.621741771697998\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:19 INFO 139724334417728] Epoch[2] Batch [5]#011Speed: 7238.89 samples/sec#011loss=15.621742\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[2] Batch[10] avg_epoch_loss=15.508645\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=15.372929191589355\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[2] Batch [10]#011Speed: 2733.41 samples/sec#011loss=15.372929\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[2] Batch[15] avg_epoch_loss=15.775688\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=16.36318359375\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[2] Batch [15]#011Speed: 7403.32 samples/sec#011loss=16.363184\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] processed a total of 1989 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067479.5836651, \"EndTime\": 1681067480.2500994, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 665.8115386962891, \"count\": 1, \"min\": 665.8115386962891, \"max\": 665.8115386962891}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2986.7981289707013 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=2, train loss <loss>=15.775688409805298\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch[0] avg_epoch_loss=15.360364\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=15.360363960266113\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch[5] avg_epoch_loss=15.058901\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=15.058900515238443\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch [5]#011Speed: 6832.84 samples/sec#011loss=15.058901\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch[10] avg_epoch_loss=15.420248\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=15.853864860534667\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch [10]#011Speed: 2846.53 samples/sec#011loss=15.853865\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch[15] avg_epoch_loss=15.765549\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=16.525209999084474\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] Epoch[3] Batch [15]#011Speed: 7400.42 samples/sec#011loss=16.525210\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] processed a total of 1937 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067480.2501814, \"EndTime\": 1681067480.8606234, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 610.0149154663086, \"count\": 1, \"min\": 610.0149154663086, \"max\": 610.0149154663086}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3174.7192344754876 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=3, train loss <loss>=15.765548586845398\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch[0] avg_epoch_loss=15.615551\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=15.615550994873047\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch[5] avg_epoch_loss=15.704768\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=15.70476802190145\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch [5]#011Speed: 7574.86 samples/sec#011loss=15.704768\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch[10] avg_epoch_loss=15.569456\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=15.407080841064452\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch [10]#011Speed: 2878.20 samples/sec#011loss=15.407081\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch[15] avg_epoch_loss=15.791999\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=16.281594657897948\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[4] Batch [15]#011Speed: 6558.20 samples/sec#011loss=16.281595\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] processed a total of 1926 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067480.8607042, \"EndTime\": 1681067481.5274343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 666.3665771484375, \"count\": 1, \"min\": 666.3665771484375, \"max\": 666.3665771484375}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2889.6744840907872 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=4, train loss <loss>=15.791999101638794\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[5] Batch[0] avg_epoch_loss=14.966464\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=14.966464042663574\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[5] Batch[5] avg_epoch_loss=15.206023\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=15.206022580464682\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:21 INFO 139724334417728] Epoch[5] Batch [5]#011Speed: 7626.66 samples/sec#011loss=15.206023\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[5] Batch[10] avg_epoch_loss=15.240597\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=15.282085609436034\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[5] Batch [10]#011Speed: 2974.28 samples/sec#011loss=15.282086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[5] Batch[15] avg_epoch_loss=15.655189\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=16.567292976379395\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[5] Batch [15]#011Speed: 7270.42 samples/sec#011loss=16.567293\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] processed a total of 1944 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067481.527542, \"EndTime\": 1681067482.1769974, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 649.0795612335205, \"count\": 1, \"min\": 649.0795612335205, \"max\": 649.0795612335205}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2994.4999748430073 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=5, train loss <loss>=15.655189275741577\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch[0] avg_epoch_loss=14.764902\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=14.764902114868164\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch[5] avg_epoch_loss=15.172395\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=15.172394752502441\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch [5]#011Speed: 7626.48 samples/sec#011loss=15.172395\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch[10] avg_epoch_loss=15.399402\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=15.67181167602539\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch [10]#011Speed: 2808.87 samples/sec#011loss=15.671812\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch[15] avg_epoch_loss=15.030400\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=14.218595504760742\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] Epoch[6] Batch [15]#011Speed: 6021.42 samples/sec#011loss=14.218596\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] processed a total of 1974 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067482.1770723, \"EndTime\": 1681067482.8576794, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 680.2380084991455, \"count\": 1, \"min\": 680.2380084991455, \"max\": 680.2380084991455}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2901.4129362997082 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:22 INFO 139724334417728] #quality_metric: host=algo-1, epoch=6, train loss <loss>=15.030400276184082\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[7] Batch[0] avg_epoch_loss=16.279799\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=16.27979850769043\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[7] Batch[5] avg_epoch_loss=15.073677\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=15.073677221934\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[7] Batch [5]#011Speed: 5302.83 samples/sec#011loss=15.073677\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[7] Batch[10] avg_epoch_loss=15.156199\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=15.255224609375\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[7] Batch [10]#011Speed: 2762.97 samples/sec#011loss=15.255225\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] processed a total of 1884 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067482.8577628, \"EndTime\": 1681067483.5842252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 725.8784770965576, \"count\": 1, \"min\": 725.8784770965576, \"max\": 725.8784770965576}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2594.5315473182686 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=7, train loss <loss>=15.1395751953125\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[8] Batch[0] avg_epoch_loss=14.968048\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=14.968048095703125\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[8] Batch[5] avg_epoch_loss=15.158102\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=15.158101876576742\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:23 INFO 139724334417728] Epoch[8] Batch [5]#011Speed: 5288.11 samples/sec#011loss=15.158102\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[8] Batch[10] avg_epoch_loss=15.121938\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=15.078541374206543\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[8] Batch [10]#011Speed: 2442.39 samples/sec#011loss=15.078541\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] processed a total of 1891 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067483.584307, \"EndTime\": 1681067484.3393033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 754.1899681091309, \"count\": 1, \"min\": 754.1899681091309, \"max\": 754.1899681091309}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2506.8772982943665 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #quality_metric: host=algo-1, epoch=8, train loss <loss>=15.337704086303711\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[9] Batch[0] avg_epoch_loss=15.144696\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=15.144696235656738\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[9] Batch[5] avg_epoch_loss=14.468319\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=14.468319257100424\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[9] Batch [5]#011Speed: 5453.26 samples/sec#011loss=14.468319\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[9] Batch[10] avg_epoch_loss=14.948379\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=15.524449920654297\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:24 INFO 139724334417728] Epoch[9] Batch [10]#011Speed: 3359.45 samples/sec#011loss=15.524450\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] processed a total of 1913 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067484.3393948, \"EndTime\": 1681067485.069852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 729.604959487915, \"count\": 1, \"min\": 729.604959487915, \"max\": 729.604959487915}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2621.571044292269 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=9, train loss <loss>=14.904735883076986\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch[0] avg_epoch_loss=14.283762\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=14.283761978149414\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch[5] avg_epoch_loss=14.903800\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=14.903799851735434\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch [5]#011Speed: 7145.13 samples/sec#011loss=14.903800\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch[10] avg_epoch_loss=14.945905\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=14.996430206298829\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch [10]#011Speed: 2782.98 samples/sec#011loss=14.996430\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch[15] avg_epoch_loss=15.021581\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=15.188068962097168\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[10] Batch [15]#011Speed: 6869.82 samples/sec#011loss=15.188069\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] processed a total of 1938 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067485.0699239, \"EndTime\": 1681067485.6829252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 612.4706268310547, \"count\": 1, \"min\": 612.4706268310547, \"max\": 612.4706268310547}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3163.636090205665 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=10, train loss <loss>=15.021580934524536\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[11] Batch[0] avg_epoch_loss=14.816928\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=14.816927909851074\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[11] Batch[5] avg_epoch_loss=14.701283\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=14.7012832959493\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:25 INFO 139724334417728] Epoch[11] Batch [5]#011Speed: 6872.70 samples/sec#011loss=14.701283\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[11] Batch[10] avg_epoch_loss=14.946860\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=15.241553115844727\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[11] Batch [10]#011Speed: 3106.88 samples/sec#011loss=15.241553\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] processed a total of 1844 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067485.6830063, \"EndTime\": 1681067486.270213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 586.8325233459473, \"count\": 1, \"min\": 586.8325233459473, \"max\": 586.8325233459473}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3141.467682588269 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=11, train loss <loss>=15.091373062133789\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch[0] avg_epoch_loss=14.983425\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=14.98342514038086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch[5] avg_epoch_loss=14.536538\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=14.536538283030191\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch [5]#011Speed: 6586.21 samples/sec#011loss=14.536538\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch[10] avg_epoch_loss=14.700390\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=14.897010993957519\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch [10]#011Speed: 2814.51 samples/sec#011loss=14.897011\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch[15] avg_epoch_loss=14.340682\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=13.54932460784912\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] Epoch[12] Batch [15]#011Speed: 7310.77 samples/sec#011loss=13.549325\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] processed a total of 1945 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067486.270319, \"EndTime\": 1681067486.9373233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 666.5403842926025, \"count\": 1, \"min\": 666.5403842926025, \"max\": 666.5403842926025}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2917.491305198356 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:26 INFO 139724334417728] #quality_metric: host=algo-1, epoch=12, train loss <loss>=14.340681731700897\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[13] Batch[0] avg_epoch_loss=15.656356\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=15.656355857849121\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[13] Batch[5] avg_epoch_loss=14.636591\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=14.636591275533041\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[13] Batch [5]#011Speed: 7424.08 samples/sec#011loss=14.636591\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[13] Batch[10] avg_epoch_loss=14.567402\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=14.484375762939454\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[13] Batch [10]#011Speed: 3611.00 samples/sec#011loss=14.484376\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] processed a total of 1904 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067486.9374104, \"EndTime\": 1681067487.487435, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 549.5531558990479, \"count\": 1, \"min\": 549.5531558990479, \"max\": 549.5531558990479}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3463.647248995836 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=13, train loss <loss>=14.70472297668457\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[14] Batch[0] avg_epoch_loss=14.544988\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=14.544987678527832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[14] Batch[5] avg_epoch_loss=14.902412\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=14.902411937713623\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:27 INFO 139724334417728] Epoch[14] Batch [5]#011Speed: 7354.11 samples/sec#011loss=14.902412\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[14] Batch[10] avg_epoch_loss=14.902467\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=14.902533340454102\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[14] Batch [10]#011Speed: 2732.70 samples/sec#011loss=14.902533\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[14] Batch[15] avg_epoch_loss=14.530902\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=13.713458156585693\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[14] Batch [15]#011Speed: 7387.91 samples/sec#011loss=13.713458\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] processed a total of 1960 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067487.487551, \"EndTime\": 1681067488.097575, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 609.4832420349121, \"count\": 1, \"min\": 609.4832420349121, \"max\": 609.4832420349121}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3215.2466355786796 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=14, train loss <loss>=14.530901819467545\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch[0] avg_epoch_loss=13.495277\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=13.495277404785156\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch[5] avg_epoch_loss=14.553714\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=14.553714434305826\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch [5]#011Speed: 7492.78 samples/sec#011loss=14.553714\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch[10] avg_epoch_loss=14.641418\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=14.746663284301757\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch [10]#011Speed: 3073.05 samples/sec#011loss=14.746663\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch[15] avg_epoch_loss=14.739922\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=14.956631088256836\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[15] Batch [15]#011Speed: 7260.64 samples/sec#011loss=14.956631\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] processed a total of 1930 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067488.0976498, \"EndTime\": 1681067488.689113, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 591.1030769348145, \"count\": 1, \"min\": 591.1030769348145, \"max\": 591.1030769348145}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3264.465753181591 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=15, train loss <loss>=14.739922404289246\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[16] Batch[0] avg_epoch_loss=14.135318\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=14.1353178024292\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[16] Batch[5] avg_epoch_loss=14.737450\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=14.73745028177897\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:28 INFO 139724334417728] Epoch[16] Batch [5]#011Speed: 7161.68 samples/sec#011loss=14.737450\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[16] Batch[10] avg_epoch_loss=14.814117\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=14.906116676330566\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[16] Batch [10]#011Speed: 2887.24 samples/sec#011loss=14.906117\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[16] Batch[15] avg_epoch_loss=15.306111\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=16.388499450683593\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[16] Batch [15]#011Speed: 7237.92 samples/sec#011loss=16.388499\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] processed a total of 1921 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067488.6891892, \"EndTime\": 1681067489.300805, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 611.2635135650635, \"count\": 1, \"min\": 611.2635135650635, \"max\": 611.2635135650635}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3142.054364340287 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=16, train loss <loss>=15.30611139535904\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch[0] avg_epoch_loss=14.320534\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=14.320533752441406\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch[5] avg_epoch_loss=14.856381\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=14.856380780537924\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch [5]#011Speed: 6866.41 samples/sec#011loss=14.856381\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch[10] avg_epoch_loss=14.584674\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=14.258626556396484\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch [10]#011Speed: 3536.15 samples/sec#011loss=14.258627\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch[15] avg_epoch_loss=14.955192\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=15.770331382751465\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] Epoch[17] Batch [15]#011Speed: 6851.43 samples/sec#011loss=15.770331\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] processed a total of 1929 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067489.300889, \"EndTime\": 1681067489.9282649, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 627.0027160644531, \"count\": 1, \"min\": 627.0027160644531, \"max\": 627.0027160644531}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3075.959217408561 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:29 INFO 139724334417728] #quality_metric: host=algo-1, epoch=17, train loss <loss>=14.955192148685455\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[18] Batch[0] avg_epoch_loss=14.368549\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=14.368549346923828\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[18] Batch[5] avg_epoch_loss=14.515953\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=14.515953381856283\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[18] Batch [5]#011Speed: 6452.15 samples/sec#011loss=14.515953\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[18] Batch[10] avg_epoch_loss=14.330996\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=14.109046173095702\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[18] Batch [10]#011Speed: 2871.11 samples/sec#011loss=14.109046\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] processed a total of 1864 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067489.9283452, \"EndTime\": 1681067490.5248244, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 596.0848331451416, \"count\": 1, \"min\": 596.0848331451416, \"max\": 596.0848331451416}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3126.405172324163 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=18, train loss <loss>=14.538752428690593\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[19] Batch[0] avg_epoch_loss=13.867332\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=13.867331504821777\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[19] Batch[5] avg_epoch_loss=14.379653\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=14.379653135935465\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:30 INFO 139724334417728] Epoch[19] Batch [5]#011Speed: 6109.36 samples/sec#011loss=14.379653\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[19] Batch[10] avg_epoch_loss=14.391284\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=14.405241203308105\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[19] Batch [10]#011Speed: 2895.63 samples/sec#011loss=14.405241\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[19] Batch[15] avg_epoch_loss=14.625225\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=15.139893531799316\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[19] Batch [15]#011Speed: 5736.98 samples/sec#011loss=15.139894\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] processed a total of 1954 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067490.524904, \"EndTime\": 1681067491.2212691, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 695.7802772521973, \"count\": 1, \"min\": 695.7802772521973, \"max\": 695.7802772521973}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2807.819048030165 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=19, train loss <loss>=14.625224530696869\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[20] Batch[0] avg_epoch_loss=15.510327\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=15.510327339172363\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[20] Batch[5] avg_epoch_loss=14.428801\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=14.428800900777182\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[20] Batch [5]#011Speed: 7584.59 samples/sec#011loss=14.428801\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[20] Batch[10] avg_epoch_loss=14.359097\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=14.275452613830566\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[20] Batch [10]#011Speed: 3559.86 samples/sec#011loss=14.275453\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] processed a total of 1909 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067491.2213614, \"EndTime\": 1681067491.7732482, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 551.3720512390137, \"count\": 1, \"min\": 551.3720512390137, \"max\": 551.3720512390137}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3461.5550017055025 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=20, train loss <loss>=14.401871744791666\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] Epoch[21] Batch[0] avg_epoch_loss=14.224072\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:31 INFO 139724334417728] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=14.224071502685547\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch[5] avg_epoch_loss=14.085832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=14.085831801096598\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch [5]#011Speed: 7514.49 samples/sec#011loss=14.085832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch[10] avg_epoch_loss=14.333384\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=14.630447387695312\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch [10]#011Speed: 3479.97 samples/sec#011loss=14.630447\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch[15] avg_epoch_loss=14.485782\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=14.82105770111084\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[21] Batch [15]#011Speed: 7295.23 samples/sec#011loss=14.821058\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] processed a total of 1972 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067491.7733188, \"EndTime\": 1681067492.328045, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 554.2094707489014, \"count\": 1, \"min\": 554.2094707489014, \"max\": 554.2094707489014}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3557.4072389685407 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=21, train loss <loss>=14.485782265663147\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch[0] avg_epoch_loss=13.974134\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=13.97413444519043\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch[5] avg_epoch_loss=14.102352\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=14.102352301279703\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch [5]#011Speed: 7533.47 samples/sec#011loss=14.102352\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch[10] avg_epoch_loss=14.303016\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=14.543813133239746\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch [10]#011Speed: 3329.11 samples/sec#011loss=14.543813\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch[15] avg_epoch_loss=14.408430\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=14.640338897705078\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] Epoch[22] Batch [15]#011Speed: 5869.94 samples/sec#011loss=14.640339\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] processed a total of 1949 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067492.3281305, \"EndTime\": 1681067492.919553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 590.9740924835205, \"count\": 1, \"min\": 590.9740924835205, \"max\": 590.9740924835205}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3297.209306903058 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:32 INFO 139724334417728] #quality_metric: host=algo-1, epoch=22, train loss <loss>=14.408429622650146\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[23] Batch[0] avg_epoch_loss=14.613682\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=14.61368179321289\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[23] Batch[5] avg_epoch_loss=14.624401\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=14.624400933583578\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[23] Batch [5]#011Speed: 7251.92 samples/sec#011loss=14.624401\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[23] Batch[10] avg_epoch_loss=14.531177\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=14.419307899475097\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[23] Batch [10]#011Speed: 3476.18 samples/sec#011loss=14.419308\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] processed a total of 1892 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067492.919645, \"EndTime\": 1681067493.478181, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 558.0742359161377, \"count\": 1, \"min\": 558.0742359161377, \"max\": 558.0742359161377}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3389.2699773980994 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=23, train loss <loss>=14.387823804219563\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[24] Batch[0] avg_epoch_loss=13.637332\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=13.63733196258545\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[24] Batch[5] avg_epoch_loss=13.955975\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=13.95597505569458\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[24] Batch [5]#011Speed: 7011.45 samples/sec#011loss=13.955975\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[24] Batch[10] avg_epoch_loss=14.144164\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=14.369990158081055\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:33 INFO 139724334417728] Epoch[24] Batch [10]#011Speed: 3615.89 samples/sec#011loss=14.369990\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] processed a total of 1879 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067493.4782972, \"EndTime\": 1681067494.039725, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 560.8985424041748, \"count\": 1, \"min\": 560.8985424041748, \"max\": 560.8985424041748}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3349.0808375955926 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=24, train loss <loss>=13.980675633748373\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch[0] avg_epoch_loss=14.302104\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=14.302103996276855\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch[5] avg_epoch_loss=14.056879\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=14.05687920252482\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch [5]#011Speed: 7486.78 samples/sec#011loss=14.056879\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch[10] avg_epoch_loss=14.564705\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=15.174094963073731\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch [10]#011Speed: 3437.64 samples/sec#011loss=15.174095\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch[15] avg_epoch_loss=13.795361\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=12.102803707122803\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[25] Batch [15]#011Speed: 6318.28 samples/sec#011loss=12.102804\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] processed a total of 1942 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067494.0398338, \"EndTime\": 1681067494.620738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 580.435037612915, \"count\": 1, \"min\": 580.435037612915, \"max\": 580.435037612915}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3344.886998436654 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=25, train loss <loss>=13.795360535383224\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[26] Batch[0] avg_epoch_loss=14.459868\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=14.459868431091309\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[26] Batch[5] avg_epoch_loss=14.295756\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=14.295756022135416\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:34 INFO 139724334417728] Epoch[26] Batch [5]#011Speed: 6829.36 samples/sec#011loss=14.295756\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[26] Batch[10] avg_epoch_loss=14.406522\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=14.53944091796875\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[26] Batch [10]#011Speed: 2926.49 samples/sec#011loss=14.539441\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[26] Batch[15] avg_epoch_loss=14.642878\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=15.162860298156739\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[26] Batch [15]#011Speed: 5773.29 samples/sec#011loss=15.162860\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] processed a total of 1963 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067494.620853, \"EndTime\": 1681067495.277249, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 655.9460163116455, \"count\": 1, \"min\": 655.9460163116455, \"max\": 655.9460163116455}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2992.120780608351 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=26, train loss <loss>=14.642877638339996\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch[0] avg_epoch_loss=12.539208\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=12.53920841217041\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch[5] avg_epoch_loss=14.024675\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=14.024675210316977\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch [5]#011Speed: 7559.77 samples/sec#011loss=14.024675\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch[10] avg_epoch_loss=14.251121\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=14.522855377197265\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch [10]#011Speed: 2711.39 samples/sec#011loss=14.522855\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch[15] avg_epoch_loss=14.558071\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=15.23336067199707\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] Epoch[27] Batch [15]#011Speed: 6955.48 samples/sec#011loss=15.233361\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] processed a total of 1965 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067495.277324, \"EndTime\": 1681067495.95043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 672.748327255249, \"count\": 1, \"min\": 672.748327255249, \"max\": 672.748327255249}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2920.330846281487 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:35 INFO 139724334417728] #quality_metric: host=algo-1, epoch=27, train loss <loss>=14.558070719242096\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[28] Batch[0] avg_epoch_loss=14.270386\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=14.2703857421875\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[28] Batch[5] avg_epoch_loss=14.068832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=14.068832079569498\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[28] Batch [5]#011Speed: 7454.04 samples/sec#011loss=14.068832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[28] Batch[10] avg_epoch_loss=14.169565\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=14.2904447555542\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[28] Batch [10]#011Speed: 3549.11 samples/sec#011loss=14.290445\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] processed a total of 1908 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067495.950513, \"EndTime\": 1681067496.4855692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 534.5890522003174, \"count\": 1, \"min\": 534.5890522003174, \"max\": 534.5890522003174}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3567.998680291174 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=28, train loss <loss>=14.146709314982097\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[29] Batch[0] avg_epoch_loss=15.196897\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=15.19689655303955\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[29] Batch[5] avg_epoch_loss=14.131697\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=14.131696701049805\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[29] Batch [5]#011Speed: 7589.12 samples/sec#011loss=14.131697\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[29] Batch[10] avg_epoch_loss=14.160605\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=14.195294952392578\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:36 INFO 139724334417728] Epoch[29] Batch [10]#011Speed: 3147.31 samples/sec#011loss=14.195295\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[29] Batch[15] avg_epoch_loss=14.166181\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=14.178446769714355\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[29] Batch [15]#011Speed: 7395.98 samples/sec#011loss=14.178447\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] processed a total of 1923 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067496.4856899, \"EndTime\": 1681067497.0783663, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 592.2689437866211, \"count\": 1, \"min\": 592.2689437866211, \"max\": 592.2689437866211}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3246.238586049417 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=29, train loss <loss>=14.166180551052094\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch[0] avg_epoch_loss=14.835573\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=14.835573196411133\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch[5] avg_epoch_loss=14.326553\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=14.326552708943685\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch [5]#011Speed: 7652.16 samples/sec#011loss=14.326553\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch[10] avg_epoch_loss=14.155288\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=13.949769973754883\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch [10]#011Speed: 3452.08 samples/sec#011loss=13.949770\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch[15] avg_epoch_loss=13.439413\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=11.864489316940308\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[30] Batch [15]#011Speed: 7245.53 samples/sec#011loss=11.864489\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] processed a total of 1934 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067497.0784438, \"EndTime\": 1681067497.6298294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 550.94313621521, \"count\": 1, \"min\": 550.94313621521, \"max\": 550.94313621521}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3509.615111476081 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=30, train loss <loss>=13.439413294196129\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[31] Batch[0] avg_epoch_loss=14.405767\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=14.405767440795898\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[31] Batch[5] avg_epoch_loss=14.412086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=14.412086327870687\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:37 INFO 139724334417728] Epoch[31] Batch [5]#011Speed: 7438.34 samples/sec#011loss=14.412086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[31] Batch[10] avg_epoch_loss=14.180232\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=13.90200595855713\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[31] Batch [10]#011Speed: 3200.06 samples/sec#011loss=13.902006\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[31] Batch[15] avg_epoch_loss=14.492864\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=15.180653953552246\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[31] Batch [15]#011Speed: 7010.35 samples/sec#011loss=15.180654\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] processed a total of 1959 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067497.6299083, \"EndTime\": 1681067498.2039404, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 573.5836029052734, \"count\": 1, \"min\": 573.5836029052734, \"max\": 573.5836029052734}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3414.674112756901 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=31, train loss <loss>=14.492863595485687\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[32] Batch[0] avg_epoch_loss=13.965364\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=13.965363502502441\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[32] Batch[5] avg_epoch_loss=14.211819\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=14.211819489796957\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[32] Batch [5]#011Speed: 7135.96 samples/sec#011loss=14.211819\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[32] Batch[10] avg_epoch_loss=14.078309\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=13.918096733093261\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[32] Batch [10]#011Speed: 3360.95 samples/sec#011loss=13.918097\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] processed a total of 1915 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067498.2040222, \"EndTime\": 1681067498.7553742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 550.9250164031982, \"count\": 1, \"min\": 550.9250164031982, \"max\": 550.9250164031982}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3475.1479841387622 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=32, train loss <loss>=14.102834002176921\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] Epoch[33] Batch[0] avg_epoch_loss=14.099017\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:38 INFO 139724334417728] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=14.099017143249512\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch[5] avg_epoch_loss=14.172349\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=14.172348658243815\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch [5]#011Speed: 5883.59 samples/sec#011loss=14.172349\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch[10] avg_epoch_loss=13.930908\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=13.64117889404297\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch [10]#011Speed: 3151.78 samples/sec#011loss=13.641179\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch[15] avg_epoch_loss=14.380405\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=15.369297409057618\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[33] Batch [15]#011Speed: 6308.97 samples/sec#011loss=15.369297\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] processed a total of 1925 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067498.7554655, \"EndTime\": 1681067499.4119825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 655.9653282165527, \"count\": 1, \"min\": 655.9653282165527, \"max\": 655.9653282165527}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2934.0784421034423 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=33, train loss <loss>=14.380404591560364\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[34] Batch[0] avg_epoch_loss=13.192999\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=13.192998886108398\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[34] Batch[5] avg_epoch_loss=13.436408\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=13.436407883961996\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[34] Batch [5]#011Speed: 7404.50 samples/sec#011loss=13.436408\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[34] Batch[10] avg_epoch_loss=13.617561\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=13.834945106506348\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:39 INFO 139724334417728] Epoch[34] Batch [10]#011Speed: 2857.54 samples/sec#011loss=13.834945\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[34] Batch[15] avg_epoch_loss=13.909726\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=14.55248966217041\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[34] Batch [15]#011Speed: 7019.90 samples/sec#011loss=14.552490\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] processed a total of 1926 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067499.4120638, \"EndTime\": 1681067500.0785396, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 666.11647605896, \"count\": 1, \"min\": 666.11647605896, \"max\": 666.11647605896}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2890.8388648250943 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=34, train loss <loss>=13.909726321697235\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch[0] avg_epoch_loss=15.098097\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=15.09809684753418\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch[5] avg_epoch_loss=14.078991\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=14.078991095225016\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch [5]#011Speed: 7132.94 samples/sec#011loss=14.078991\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch[10] avg_epoch_loss=14.023988\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=13.957984352111817\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch [10]#011Speed: 3630.20 samples/sec#011loss=13.957984\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch[15] avg_epoch_loss=13.992736\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=13.923981857299804\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[35] Batch [15]#011Speed: 6271.67 samples/sec#011loss=13.923982\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] processed a total of 1929 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067500.0786278, \"EndTime\": 1681067500.6512678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 572.2806453704834, \"count\": 1, \"min\": 572.2806453704834, \"max\": 572.2806453704834}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3369.7425075530464 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=35, train loss <loss>=13.992736101150513\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[36] Batch[0] avg_epoch_loss=13.533956\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=13.533955574035645\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[36] Batch[5] avg_epoch_loss=13.784631\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=13.784631252288818\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:40 INFO 139724334417728] Epoch[36] Batch [5]#011Speed: 7022.20 samples/sec#011loss=13.784631\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[36] Batch[10] avg_epoch_loss=13.744067\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=13.695389556884766\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[36] Batch [10]#011Speed: 2917.02 samples/sec#011loss=13.695390\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] processed a total of 1918 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067500.6513972, \"EndTime\": 1681067501.2468212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 594.9742794036865, \"count\": 1, \"min\": 594.9742794036865, \"max\": 594.9742794036865}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3223.0087940211874 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=36, train loss <loss>=13.956201807657878\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch[0] avg_epoch_loss=13.800149\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=13.800148963928223\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch[5] avg_epoch_loss=13.585320\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=13.585320472717285\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch [5]#011Speed: 7506.90 samples/sec#011loss=13.585320\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch[10] avg_epoch_loss=13.574604\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=13.561743545532227\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch [10]#011Speed: 3412.79 samples/sec#011loss=13.561744\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch[15] avg_epoch_loss=13.324713\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=12.774953842163086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] Epoch[37] Batch [15]#011Speed: 7414.34 samples/sec#011loss=12.774954\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] processed a total of 1954 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067501.2469, \"EndTime\": 1681067501.809316, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 561.9187355041504, \"count\": 1, \"min\": 561.9187355041504, \"max\": 561.9187355041504}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3476.6409680688466 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:41 INFO 139724334417728] #quality_metric: host=algo-1, epoch=37, train loss <loss>=13.324713110923767\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch[0] avg_epoch_loss=13.073586\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=13.073586463928223\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch[5] avg_epoch_loss=13.299140\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=13.299139658610025\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch [5]#011Speed: 7605.89 samples/sec#011loss=13.299140\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch[10] avg_epoch_loss=13.463994\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=13.661819648742675\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch [10]#011Speed: 3443.12 samples/sec#011loss=13.661820\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch[15] avg_epoch_loss=13.750143\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=14.379669570922852\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[38] Batch [15]#011Speed: 6327.53 samples/sec#011loss=14.379670\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] processed a total of 1967 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067501.8093967, \"EndTime\": 1681067502.38865, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 578.8779258728027, \"count\": 1, \"min\": 578.8779258728027, \"max\": 578.8779258728027}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3397.162497040421 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=38, train loss <loss>=13.750142753124237\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch[0] avg_epoch_loss=13.943236\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=13.943236351013184\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch[5] avg_epoch_loss=14.154408\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=14.154407978057861\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch [5]#011Speed: 6490.78 samples/sec#011loss=14.154408\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch[10] avg_epoch_loss=14.010834\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=13.838544273376465\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch [10]#011Speed: 3608.67 samples/sec#011loss=13.838544\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch[15] avg_epoch_loss=13.948617\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=13.811738967895508\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] Epoch[39] Batch [15]#011Speed: 6886.99 samples/sec#011loss=13.811739\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] processed a total of 1921 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067502.3887436, \"EndTime\": 1681067502.9646685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 575.3457546234131, \"count\": 1, \"min\": 575.3457546234131, \"max\": 575.3457546234131}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3338.2144683368665 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:42 INFO 139724334417728] #quality_metric: host=algo-1, epoch=39, train loss <loss>=13.94861650466919\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch[0] avg_epoch_loss=13.483889\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=13.483888626098633\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch[5] avg_epoch_loss=13.678224\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=13.678223609924316\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch [5]#011Speed: 7493.78 samples/sec#011loss=13.678224\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch[10] avg_epoch_loss=13.888457\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=14.140736961364746\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch [10]#011Speed: 2900.22 samples/sec#011loss=14.140737\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch[15] avg_epoch_loss=13.124135\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=11.442625522613525\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[40] Batch [15]#011Speed: 7272.25 samples/sec#011loss=11.442626\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] processed a total of 1930 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067502.964742, \"EndTime\": 1681067503.6199925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 654.897928237915, \"count\": 1, \"min\": 654.897928237915, \"max\": 654.897928237915}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2946.5242581189505 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=40, train loss <loss>=13.124134629964828\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[41] Batch[0] avg_epoch_loss=13.431932\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=13.43193244934082\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[41] Batch[5] avg_epoch_loss=13.633400\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=13.633400122324625\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:43 INFO 139724334417728] Epoch[41] Batch [5]#011Speed: 7461.47 samples/sec#011loss=13.633400\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[41] Batch[10] avg_epoch_loss=13.754332\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=13.899451065063477\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[41] Batch [10]#011Speed: 3266.44 samples/sec#011loss=13.899451\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] processed a total of 1886 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067503.6200678, \"EndTime\": 1681067504.2323792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 611.7970943450928, \"count\": 1, \"min\": 611.7970943450928, \"max\": 611.7970943450928}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3082.1028404357867 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=41, train loss <loss>=13.709730402628582\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch[0] avg_epoch_loss=12.689167\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=12.689167022705078\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch[5] avg_epoch_loss=13.583558\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=13.583558241526285\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch [5]#011Speed: 7486.84 samples/sec#011loss=13.583558\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch[10] avg_epoch_loss=13.434490\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=13.255607414245606\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch [10]#011Speed: 3412.34 samples/sec#011loss=13.255607\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch[15] avg_epoch_loss=12.998523\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=12.039396858215332\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] Epoch[42] Batch [15]#011Speed: 5938.23 samples/sec#011loss=12.039397\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] processed a total of 1945 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067504.2324636, \"EndTime\": 1681067504.8729508, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 640.0513648986816, \"count\": 1, \"min\": 640.0513648986816, \"max\": 640.0513648986816}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3038.245949090454 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:44 INFO 139724334417728] #quality_metric: host=algo-1, epoch=42, train loss <loss>=12.9985231757164\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[43] Batch[0] avg_epoch_loss=14.455032\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=14.455032348632812\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[43] Batch[5] avg_epoch_loss=13.672995\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=13.67299509048462\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[43] Batch [5]#011Speed: 7128.78 samples/sec#011loss=13.672995\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[43] Batch[10] avg_epoch_loss=13.585177\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=13.479794311523438\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[43] Batch [10]#011Speed: 2924.04 samples/sec#011loss=13.479794\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] processed a total of 1912 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067504.8730378, \"EndTime\": 1681067505.4526324, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 579.1687965393066, \"count\": 1, \"min\": 579.1687965393066, \"max\": 579.1687965393066}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3300.2693250412763 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=43, train loss <loss>=13.591481653849284\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[44] Batch[0] avg_epoch_loss=13.111027\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=13.111026763916016\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[44] Batch[5] avg_epoch_loss=13.335893\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=13.335892677307129\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:45 INFO 139724334417728] Epoch[44] Batch [5]#011Speed: 7585.86 samples/sec#011loss=13.335893\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[44] Batch[10] avg_epoch_loss=13.431672\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=13.546606636047363\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[44] Batch [10]#011Speed: 3049.43 samples/sec#011loss=13.546607\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] processed a total of 1892 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067505.4527698, \"EndTime\": 1681067506.0946755, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 641.4496898651123, \"count\": 1, \"min\": 641.4496898651123, \"max\": 641.4496898651123}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2948.789537245471 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=44, train loss <loss>=13.611482048034668\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch[0] avg_epoch_loss=14.124969\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=14.124968528747559\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch[5] avg_epoch_loss=13.530045\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=13.53004535039266\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch [5]#011Speed: 7369.44 samples/sec#011loss=13.530045\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch[10] avg_epoch_loss=13.631800\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=13.753906059265137\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch [10]#011Speed: 3338.48 samples/sec#011loss=13.753906\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch[15] avg_epoch_loss=13.966801\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=14.703802490234375\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[45] Batch [15]#011Speed: 7397.75 samples/sec#011loss=14.703802\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] processed a total of 1937 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067506.0948002, \"EndTime\": 1681067506.6668584, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 571.530818939209, \"count\": 1, \"min\": 571.530818939209, \"max\": 571.530818939209}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3388.4919297557803 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=45, train loss <loss>=13.966800928115845\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] Epoch[46] Batch[0] avg_epoch_loss=13.506459\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:46 INFO 139724334417728] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=13.50645923614502\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[46] Batch[5] avg_epoch_loss=13.262391\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=13.262391090393066\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[46] Batch [5]#011Speed: 7285.30 samples/sec#011loss=13.262391\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[46] Batch[10] avg_epoch_loss=13.353064\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=13.461871337890624\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[46] Batch [10]#011Speed: 3587.85 samples/sec#011loss=13.461871\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] processed a total of 1896 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067506.6669343, \"EndTime\": 1681067507.2678013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 600.4927158355713, \"count\": 1, \"min\": 600.4927158355713, \"max\": 600.4927158355713}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3156.7466441407823 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=46, train loss <loss>=13.498300743103027\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[47] Batch[0] avg_epoch_loss=14.055464\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=14.055463790893555\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[47] Batch[5] avg_epoch_loss=13.241704\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=13.24170446395874\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[47] Batch [5]#011Speed: 5825.03 samples/sec#011loss=13.241704\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[47] Batch[10] avg_epoch_loss=13.344253\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=13.46731128692627\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] Epoch[47] Batch [10]#011Speed: 2720.44 samples/sec#011loss=13.467311\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] processed a total of 1919 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067507.2678878, \"EndTime\": 1681067507.9196758, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 651.3333320617676, \"count\": 1, \"min\": 651.3333320617676, \"max\": 651.3333320617676}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2945.699069028339 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:47 INFO 139724334417728] #quality_metric: host=algo-1, epoch=47, train loss <loss>=13.418320719401041\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[48] Batch[0] avg_epoch_loss=13.866183\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=13.866183280944824\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[48] Batch[5] avg_epoch_loss=13.640022\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=13.64002243677775\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[48] Batch [5]#011Speed: 5765.91 samples/sec#011loss=13.640022\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[48] Batch[10] avg_epoch_loss=13.496909\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=13.325173568725585\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[48] Batch [10]#011Speed: 2852.35 samples/sec#011loss=13.325174\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] processed a total of 1904 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067507.9197636, \"EndTime\": 1681067508.5654917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 645.3406810760498, \"count\": 1, \"min\": 645.3406810760498, \"max\": 645.3406810760498}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2949.79986089395 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=48, train loss <loss>=13.47908420562744\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[49] Batch[0] avg_epoch_loss=12.516347\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=12.51634693145752\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[49] Batch[5] avg_epoch_loss=13.230961\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=13.230961481730143\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:48 INFO 139724334417728] Epoch[49] Batch [5]#011Speed: 7382.73 samples/sec#011loss=13.230961\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[49] Batch[10] avg_epoch_loss=13.287644\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=13.355663108825684\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[49] Batch [10]#011Speed: 2743.87 samples/sec#011loss=13.355663\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[49] Batch[15] avg_epoch_loss=13.433206\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=13.753443145751953\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[49] Batch [15]#011Speed: 7163.05 samples/sec#011loss=13.753443\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] processed a total of 1949 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067508.5655806, \"EndTime\": 1681067509.2333944, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 667.137622833252, \"count\": 1, \"min\": 667.137622833252, \"max\": 667.137622833252}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2920.951838784668 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=49, train loss <loss>=13.433206260204315\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[50] Batch[0] avg_epoch_loss=13.158042\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=13.158041954040527\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[50] Batch[5] avg_epoch_loss=13.476676\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=13.476676305135092\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[50] Batch [5]#011Speed: 5940.74 samples/sec#011loss=13.476676\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[50] Batch[10] avg_epoch_loss=13.534658\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=13.604236793518066\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] Epoch[50] Batch [10]#011Speed: 2950.14 samples/sec#011loss=13.604237\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] processed a total of 1866 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067509.2334692, \"EndTime\": 1681067509.844807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 610.950231552124, \"count\": 1, \"min\": 610.950231552124, \"max\": 610.950231552124}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3053.703277087543 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:49 INFO 139724334417728] #quality_metric: host=algo-1, epoch=50, train loss <loss>=13.596161905924479\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[51] Batch[0] avg_epoch_loss=13.136678\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=13.136677742004395\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[51] Batch[5] avg_epoch_loss=13.312702\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=13.312701543172201\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[51] Batch [5]#011Speed: 5795.85 samples/sec#011loss=13.312702\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[51] Batch[10] avg_epoch_loss=13.356156\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=13.408302307128906\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[51] Batch [10]#011Speed: 3123.32 samples/sec#011loss=13.408302\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] processed a total of 1901 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067509.8448777, \"EndTime\": 1681067510.4332552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 587.9092216491699, \"count\": 1, \"min\": 587.9092216491699, \"max\": 587.9092216491699}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3232.7674141864554 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=51, train loss <loss>=13.507598241170248\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[52] Batch[0] avg_epoch_loss=12.670890\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=12.670889854431152\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[52] Batch[5] avg_epoch_loss=13.623518\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=13.623517513275146\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:50 INFO 139724334417728] Epoch[52] Batch [5]#011Speed: 7643.73 samples/sec#011loss=13.623518\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[52] Batch[10] avg_epoch_loss=13.535518\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=13.429918670654297\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[52] Batch [10]#011Speed: 2903.57 samples/sec#011loss=13.429919\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] processed a total of 1918 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067510.433348, \"EndTime\": 1681067511.072397, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 638.6308670043945, \"count\": 1, \"min\": 638.6308670043945, \"max\": 638.6308670043945}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3002.715830830347 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=52, train loss <loss>=13.550045013427734\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[53] Batch[0] avg_epoch_loss=11.725371\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=11.725371360778809\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[53] Batch[5] avg_epoch_loss=13.379285\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=13.379285335540771\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[53] Batch [5]#011Speed: 7346.37 samples/sec#011loss=13.379285\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[53] Batch[10] avg_epoch_loss=13.498529\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=13.641622161865234\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[53] Batch [10]#011Speed: 2878.17 samples/sec#011loss=13.641622\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] processed a total of 1912 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067511.0724838, \"EndTime\": 1681067511.719084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 646.2078094482422, \"count\": 1, \"min\": 646.2078094482422, \"max\": 646.2078094482422}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2958.2187806744932 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=53, train loss <loss>=13.435951232910156\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] Epoch[54] Batch[0] avg_epoch_loss=14.532375\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:51 INFO 139724334417728] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=14.53237533569336\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[54] Batch[5] avg_epoch_loss=13.234418\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=13.234418074289957\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[54] Batch [5]#011Speed: 7526.33 samples/sec#011loss=13.234418\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[54] Batch[10] avg_epoch_loss=13.332442\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=13.450070190429688\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[54] Batch [10]#011Speed: 3503.82 samples/sec#011loss=13.450070\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] processed a total of 1912 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067511.7191637, \"EndTime\": 1681067512.3331342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 613.5704517364502, \"count\": 1, \"min\": 613.5704517364502, \"max\": 613.5704517364502}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3115.5667232449873 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=54, train loss <loss>=13.277088101704916\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[55] Batch[0] avg_epoch_loss=13.332870\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=13.332869529724121\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[55] Batch[5] avg_epoch_loss=13.005725\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=13.005725224812826\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[55] Batch [5]#011Speed: 6131.39 samples/sec#011loss=13.005725\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[55] Batch[10] avg_epoch_loss=12.962517\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=12.91066780090332\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] Epoch[55] Batch [10]#011Speed: 3440.09 samples/sec#011loss=12.910668\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] processed a total of 1860 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067512.3332176, \"EndTime\": 1681067512.8987422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 565.0420188903809, \"count\": 1, \"min\": 565.0420188903809, \"max\": 565.0420188903809}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3291.133738969833 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:52 INFO 139724334417728] #quality_metric: host=algo-1, epoch=55, train loss <loss>=13.156707572937012\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch[0] avg_epoch_loss=13.600017\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=13.600016593933105\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch[5] avg_epoch_loss=13.293634\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=13.293633937835693\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch [5]#011Speed: 7566.10 samples/sec#011loss=13.293634\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch[10] avg_epoch_loss=13.109590\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=12.888736724853516\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch [10]#011Speed: 2858.46 samples/sec#011loss=12.888737\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch[15] avg_epoch_loss=12.728882\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=11.891326141357421\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[56] Batch [15]#011Speed: 7365.94 samples/sec#011loss=11.891326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] processed a total of 1953 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067512.8988202, \"EndTime\": 1681067513.5554564, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 656.2395095825195, \"count\": 1, \"min\": 656.2395095825195, \"max\": 656.2395095825195}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2975.5535337867905 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=56, train loss <loss>=12.728882372379303\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[57] Batch[0] avg_epoch_loss=12.803872\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=12.803872108459473\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[57] Batch[5] avg_epoch_loss=13.181616\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=13.181616306304932\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:53 INFO 139724334417728] Epoch[57] Batch [5]#011Speed: 5795.33 samples/sec#011loss=13.181616\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[57] Batch[10] avg_epoch_loss=13.225048\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=13.277166175842286\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[57] Batch [10]#011Speed: 3176.01 samples/sec#011loss=13.277166\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] processed a total of 1917 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067513.555531, \"EndTime\": 1681067514.1479142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 592.0135974884033, \"count\": 1, \"min\": 592.0135974884033, \"max\": 592.0135974884033}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3237.4520070398294 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=57, train loss <loss>=13.288496017456055\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[58] Batch[0] avg_epoch_loss=13.808165\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=13.808164596557617\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[58] Batch[5] avg_epoch_loss=13.610842\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=13.610841751098633\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[58] Batch [5]#011Speed: 7510.32 samples/sec#011loss=13.610842\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[58] Batch[10] avg_epoch_loss=13.423635\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=13.198986053466797\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[58] Batch [10]#011Speed: 3077.26 samples/sec#011loss=13.198986\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] processed a total of 1879 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067514.1479905, \"EndTime\": 1681067514.7216444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 573.1902122497559, \"count\": 1, \"min\": 573.1902122497559, \"max\": 573.1902122497559}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3276.982575366343 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=58, train loss <loss>=13.624185562133789\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] Epoch[59] Batch[0] avg_epoch_loss=14.467380\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:54 INFO 139724334417728] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=14.467379570007324\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch[5] avg_epoch_loss=13.412135\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=13.412134647369385\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch [5]#011Speed: 7635.46 samples/sec#011loss=13.412135\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch[10] avg_epoch_loss=13.334515\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=13.241371536254883\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch [10]#011Speed: 3532.11 samples/sec#011loss=13.241372\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch[15] avg_epoch_loss=13.461327\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=13.740311813354491\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[59] Batch [15]#011Speed: 7380.46 samples/sec#011loss=13.740312\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] processed a total of 1938 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067514.7218046, \"EndTime\": 1681067515.2775578, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 555.227518081665, \"count\": 1, \"min\": 555.227518081665, \"max\": 555.227518081665}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3489.6862813451194 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=59, train loss <loss>=13.461326539516449\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[60] Batch[0] avg_epoch_loss=13.114149\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=13.11414909362793\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[60] Batch[5] avg_epoch_loss=12.947564\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=12.947563966115316\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[60] Batch [5]#011Speed: 7482.81 samples/sec#011loss=12.947564\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[60] Batch[10] avg_epoch_loss=13.096735\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=13.275741004943848\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] Epoch[60] Batch [10]#011Speed: 3627.11 samples/sec#011loss=13.275741\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] processed a total of 1896 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067515.2776427, \"EndTime\": 1681067515.8113627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 533.280611038208, \"count\": 1, \"min\": 533.280611038208, \"max\": 533.280611038208}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3554.2169044740563 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:55 INFO 139724334417728] #quality_metric: host=algo-1, epoch=60, train loss <loss>=13.266406059265137\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[61] Batch[0] avg_epoch_loss=13.431827\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=13.4318265914917\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[61] Batch[5] avg_epoch_loss=13.262484\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=13.262484391530355\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[61] Batch [5]#011Speed: 7311.27 samples/sec#011loss=13.262484\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[61] Batch[10] avg_epoch_loss=13.498870\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=13.782532691955566\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[61] Batch [10]#011Speed: 2963.71 samples/sec#011loss=13.782533\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] processed a total of 1892 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067515.8114324, \"EndTime\": 1681067516.389461, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 577.4264335632324, \"count\": 1, \"min\": 577.4264335632324, \"max\": 577.4264335632324}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3275.846366407771 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=61, train loss <loss>=13.539122645060221\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[62] Batch[0] avg_epoch_loss=14.314544\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=14.314543724060059\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[62] Batch[5] avg_epoch_loss=13.376132\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=13.376131693522135\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:56 INFO 139724334417728] Epoch[62] Batch [5]#011Speed: 5711.23 samples/sec#011loss=13.376132\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[62] Batch[10] avg_epoch_loss=13.607385\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=13.884888076782227\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[62] Batch [10]#011Speed: 2731.32 samples/sec#011loss=13.884888\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[62] Batch[15] avg_epoch_loss=12.777708\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=10.952420139312744\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[62] Batch [15]#011Speed: 7185.64 samples/sec#011loss=10.952420\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] processed a total of 1935 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067516.3895457, \"EndTime\": 1681067517.090012, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 700.0613212585449, \"count\": 1, \"min\": 700.0613212585449, \"max\": 700.0613212585449}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2763.615333407112 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=62, train loss <loss>=12.77770820260048\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch[0] avg_epoch_loss=13.569221\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=13.569221496582031\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch[5] avg_epoch_loss=13.756654\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=13.756654421488443\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch [5]#011Speed: 7077.39 samples/sec#011loss=13.756654\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch[10] avg_epoch_loss=13.762228\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=13.768916130065918\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch [10]#011Speed: 2937.50 samples/sec#011loss=13.768916\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch[15] avg_epoch_loss=13.748712\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=13.718977165222167\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[63] Batch [15]#011Speed: 5697.51 samples/sec#011loss=13.718977\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] processed a total of 1974 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067517.0900853, \"EndTime\": 1681067517.711231, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 620.7058429718018, \"count\": 1, \"min\": 620.7058429718018, \"max\": 620.7058429718018}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3179.611642610924 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=63, train loss <loss>=13.748712062835693\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] Epoch[64] Batch[0] avg_epoch_loss=12.491362\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:57 INFO 139724334417728] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=12.491361618041992\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[64] Batch[5] avg_epoch_loss=13.029701\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=13.02970059712728\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[64] Batch [5]#011Speed: 5995.13 samples/sec#011loss=13.029701\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[64] Batch[10] avg_epoch_loss=13.120038\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=13.228442764282226\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[64] Batch [10]#011Speed: 2877.77 samples/sec#011loss=13.228443\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] processed a total of 1919 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067517.711317, \"EndTime\": 1681067518.3172684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 605.5066585540771, \"count\": 1, \"min\": 605.5066585540771, \"max\": 605.5066585540771}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3168.61168385962 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=64, train loss <loss>=13.287192026774088\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch[0] avg_epoch_loss=12.293270\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=12.293270111083984\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch[5] avg_epoch_loss=12.998457\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=12.998457431793213\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch [5]#011Speed: 6149.67 samples/sec#011loss=12.998457\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch[10] avg_epoch_loss=13.129069\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=13.285803604125977\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch [10]#011Speed: 3231.11 samples/sec#011loss=13.285804\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch[15] avg_epoch_loss=13.476637\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=14.241284942626953\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] Epoch[65] Batch [15]#011Speed: 6967.97 samples/sec#011loss=14.241285\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] processed a total of 1935 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067518.3173482, \"EndTime\": 1681067518.975959, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 658.2126617431641, \"count\": 1, \"min\": 658.2126617431641, \"max\": 658.2126617431641}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2939.2949367285732 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:58 INFO 139724334417728] #quality_metric: host=algo-1, epoch=65, train loss <loss>=13.476636707782745\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[66] Batch[0] avg_epoch_loss=13.085326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=13.085326194763184\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[66] Batch[5] avg_epoch_loss=13.320747\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=13.320746580759684\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[66] Batch [5]#011Speed: 6941.99 samples/sec#011loss=13.320747\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[66] Batch[10] avg_epoch_loss=13.285623\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=13.243474388122559\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[66] Batch [10]#011Speed: 3353.70 samples/sec#011loss=13.243474\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] processed a total of 1916 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067518.976033, \"EndTime\": 1681067519.5420814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 565.6824111938477, \"count\": 1, \"min\": 565.6824111938477, \"max\": 565.6824111938477}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3386.233179098635 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=66, train loss <loss>=13.335481643676758\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[67] Batch[0] avg_epoch_loss=13.711001\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=13.7110013961792\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[67] Batch[5] avg_epoch_loss=13.664740\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=13.664739926656088\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:11:59 INFO 139724334417728] Epoch[67] Batch [5]#011Speed: 5707.08 samples/sec#011loss=13.664740\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[67] Batch[10] avg_epoch_loss=13.360957\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=12.996416473388672\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[67] Batch [10]#011Speed: 2726.33 samples/sec#011loss=12.996416\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[67] Batch[15] avg_epoch_loss=13.323608\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=13.241440582275391\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[67] Batch [15]#011Speed: 7102.88 samples/sec#011loss=13.241441\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] processed a total of 1938 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067519.5421786, \"EndTime\": 1681067520.1879473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 645.1890468597412, \"count\": 1, \"min\": 645.1890468597412, \"max\": 645.1890468597412}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3003.218095504462 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=67, train loss <loss>=13.323607802391052\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch[0] avg_epoch_loss=12.374949\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=12.37494945526123\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch[5] avg_epoch_loss=13.188629\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=13.188628514607748\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch [5]#011Speed: 6744.78 samples/sec#011loss=13.188629\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch[10] avg_epoch_loss=13.319495\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=13.476534652709962\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch [10]#011Speed: 3424.61 samples/sec#011loss=13.476535\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch[15] avg_epoch_loss=13.340679\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=13.387282562255859\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] Epoch[68] Batch [15]#011Speed: 7202.82 samples/sec#011loss=13.387283\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] processed a total of 1931 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067520.18803, \"EndTime\": 1681067520.8239849, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 635.5788707733154, \"count\": 1, \"min\": 635.5788707733154, \"max\": 635.5788707733154}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3037.5770435534005 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #progress_metric: host=algo-1, completed 69.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:00 INFO 139724334417728] #quality_metric: host=algo-1, epoch=68, train loss <loss>=13.340678572654724\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch[0] avg_epoch_loss=13.061817\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=13.061817169189453\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch[5] avg_epoch_loss=13.180279\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=13.18027925491333\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch [5]#011Speed: 5574.75 samples/sec#011loss=13.180279\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch[10] avg_epoch_loss=13.267073\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=13.37122459411621\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch [10]#011Speed: 2530.78 samples/sec#011loss=13.371225\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch[15] avg_epoch_loss=13.436960\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=13.810712432861328\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[69] Batch [15]#011Speed: 6063.41 samples/sec#011loss=13.810712\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] processed a total of 1955 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067520.8240688, \"EndTime\": 1681067521.4966662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 672.0964908599854, \"count\": 1, \"min\": 672.0964908599854, \"max\": 672.0964908599854}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2908.164779342893 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=69, train loss <loss>=13.43696004152298\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[70] Batch[0] avg_epoch_loss=13.331727\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=13.331727027893066\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[70] Batch[5] avg_epoch_loss=13.450486\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=13.450486183166504\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:01 INFO 139724334417728] Epoch[70] Batch [5]#011Speed: 6217.96 samples/sec#011loss=13.450486\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[70] Batch[10] avg_epoch_loss=13.429908\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=13.405213356018066\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[70] Batch [10]#011Speed: 3335.53 samples/sec#011loss=13.405213\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] processed a total of 1904 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067521.4967635, \"EndTime\": 1681067522.0969086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 599.2372035980225, \"count\": 1, \"min\": 599.2372035980225, \"max\": 599.2372035980225}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3176.8191991394774 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #progress_metric: host=algo-1, completed 71.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=70, train loss <loss>=13.530071703592936\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[71] Batch[0] avg_epoch_loss=12.743815\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=12.743815422058105\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[71] Batch[5] avg_epoch_loss=13.170629\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=13.170629183451334\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[71] Batch [5]#011Speed: 6590.30 samples/sec#011loss=13.170629\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[71] Batch[10] avg_epoch_loss=13.093500\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=13.000944709777832\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] Epoch[71] Batch [10]#011Speed: 2845.51 samples/sec#011loss=13.000945\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] processed a total of 1909 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067522.0969784, \"EndTime\": 1681067522.7420735, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 644.1230773925781, \"count\": 1, \"min\": 644.1230773925781, \"max\": 644.1230773925781}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2962.374988993198 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:02 INFO 139724334417728] #quality_metric: host=algo-1, epoch=71, train loss <loss>=13.177625910441082\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch[0] avg_epoch_loss=13.817912\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=13.817912101745605\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch[5] avg_epoch_loss=13.065161\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=13.065161228179932\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch [5]#011Speed: 4822.81 samples/sec#011loss=13.065161\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch[10] avg_epoch_loss=13.147017\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=13.245244789123536\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch [10]#011Speed: 2456.94 samples/sec#011loss=13.245245\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch[15] avg_epoch_loss=13.458508\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=72, batch=15 train loss <loss>=14.143786430358887\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[72] Batch [15]#011Speed: 5101.74 samples/sec#011loss=14.143786\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] processed a total of 1950 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067522.7423167, \"EndTime\": 1681067523.5340872, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 790.9336090087891, \"count\": 1, \"min\": 790.9336090087891, \"max\": 790.9336090087891}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2465.0328740658806 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #progress_metric: host=algo-1, completed 73.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=72, train loss <loss>=13.458507716655731\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[73] Batch[0] avg_epoch_loss=12.035468\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=12.035468101501465\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[73] Batch[5] avg_epoch_loss=13.303658\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=13.303658326466879\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:03 INFO 139724334417728] Epoch[73] Batch [5]#011Speed: 5873.67 samples/sec#011loss=13.303658\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[73] Batch[10] avg_epoch_loss=13.303710\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=13.303771018981934\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[73] Batch [10]#011Speed: 2817.60 samples/sec#011loss=13.303771\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] processed a total of 1882 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067523.5341754, \"EndTime\": 1681067524.1495152, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 614.8586273193359, \"count\": 1, \"min\": 614.8586273193359, \"max\": 614.8586273193359}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3060.236109070397 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #progress_metric: host=algo-1, completed 74.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=73, train loss <loss>=13.349694887797037\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[74] Batch[0] avg_epoch_loss=13.073905\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=13.073904991149902\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[74] Batch[5] avg_epoch_loss=13.320046\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=13.320046424865723\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[74] Batch [5]#011Speed: 7352.18 samples/sec#011loss=13.320046\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[74] Batch[10] avg_epoch_loss=13.202782\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=13.062065124511719\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] Epoch[74] Batch [10]#011Speed: 2831.65 samples/sec#011loss=13.062065\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] processed a total of 1920 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067524.1496024, \"EndTime\": 1681067524.7996085, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 649.5873928070068, \"count\": 1, \"min\": 649.5873928070068, \"max\": 649.5873928070068}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2955.138858869658 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:04 INFO 139724334417728] #quality_metric: host=algo-1, epoch=74, train loss <loss>=13.254927317301432\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch[0] avg_epoch_loss=13.860196\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=13.860196113586426\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch[5] avg_epoch_loss=13.610448\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=13.610447565714518\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch [5]#011Speed: 7351.98 samples/sec#011loss=13.610448\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch[10] avg_epoch_loss=13.486767\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=13.338350677490235\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch [10]#011Speed: 2845.85 samples/sec#011loss=13.338351\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch[15] avg_epoch_loss=13.750727\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=75, batch=15 train loss <loss>=14.331439399719239\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[75] Batch [15]#011Speed: 7424.02 samples/sec#011loss=14.331439\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] processed a total of 1921 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067524.799697, \"EndTime\": 1681067525.459933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 659.754753112793, \"count\": 1, \"min\": 659.754753112793, \"max\": 659.754753112793}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2911.173563907373 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=75, train loss <loss>=13.750727236270905\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[76] Batch[0] avg_epoch_loss=12.799559\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=12.799558639526367\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[76] Batch[5] avg_epoch_loss=13.319972\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=13.319972356160482\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[76] Batch [5]#011Speed: 6390.03 samples/sec#011loss=13.319972\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[76] Batch[10] avg_epoch_loss=13.352323\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=13.391143226623536\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:05 INFO 139724334417728] Epoch[76] Batch [10]#011Speed: 2815.55 samples/sec#011loss=13.391143\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[76] Batch[15] avg_epoch_loss=13.691326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=76, batch=15 train loss <loss>=14.437132644653321\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[76] Batch [15]#011Speed: 6872.04 samples/sec#011loss=14.437133\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] processed a total of 1951 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067525.4600143, \"EndTime\": 1681067526.090461, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 630.0795078277588, \"count\": 1, \"min\": 630.0795078277588, \"max\": 630.0795078277588}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3095.746998106935 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #progress_metric: host=algo-1, completed 77.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=76, train loss <loss>=13.691325843334198\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[77] Batch[0] avg_epoch_loss=14.211609\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=14.21160888671875\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[77] Batch[5] avg_epoch_loss=13.315482\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=13.315482457478842\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[77] Batch [5]#011Speed: 7221.81 samples/sec#011loss=13.315482\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[77] Batch[10] avg_epoch_loss=13.241562\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=13.152856636047364\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[77] Batch [10]#011Speed: 2924.77 samples/sec#011loss=13.152857\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] processed a total of 1888 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067526.0905626, \"EndTime\": 1681067526.6805842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 589.4603729248047, \"count\": 1, \"min\": 589.4603729248047, \"max\": 589.4603729248047}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3202.254664064051 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #progress_metric: host=algo-1, completed 78.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=77, train loss <loss>=13.326175308227539\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[78] Batch[0] avg_epoch_loss=12.813601\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=12.81360149383545\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[78] Batch[5] avg_epoch_loss=13.084570\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=13.084569613138834\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:06 INFO 139724334417728] Epoch[78] Batch [5]#011Speed: 6146.53 samples/sec#011loss=13.084570\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[78] Batch[10] avg_epoch_loss=13.198488\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=13.335189056396484\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[78] Batch [10]#011Speed: 3687.36 samples/sec#011loss=13.335189\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] processed a total of 1890 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067526.6806648, \"EndTime\": 1681067527.2388773, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 557.6484203338623, \"count\": 1, \"min\": 557.6484203338623, \"max\": 557.6484203338623}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3388.3948921255383 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #progress_metric: host=algo-1, completed 79.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=78, train loss <loss>=13.329807217915853\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[79] Batch[0] avg_epoch_loss=12.318997\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=12.318997383117676\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[79] Batch[5] avg_epoch_loss=13.019051\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=13.019051392873129\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[79] Batch [5]#011Speed: 5899.12 samples/sec#011loss=13.019051\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[79] Batch[10] avg_epoch_loss=13.088152\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=13.171073532104492\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] Epoch[79] Batch [10]#011Speed: 2924.48 samples/sec#011loss=13.171074\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] processed a total of 1883 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067527.2389731, \"EndTime\": 1681067527.8623323, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 622.861385345459, \"count\": 1, \"min\": 622.861385345459, \"max\": 622.861385345459}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3022.495497374505 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:07 INFO 139724334417728] #quality_metric: host=algo-1, epoch=79, train loss <loss>=12.977336247762045\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch[0] avg_epoch_loss=13.292109\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=13.292108535766602\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch[5] avg_epoch_loss=13.107373\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=13.107373078664144\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch [5]#011Speed: 7464.27 samples/sec#011loss=13.107373\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch[10] avg_epoch_loss=13.017619\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=12.909913063049316\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch [10]#011Speed: 3324.39 samples/sec#011loss=12.909913\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch[15] avg_epoch_loss=13.265788\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=80, batch=15 train loss <loss>=13.811759757995606\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[80] Batch [15]#011Speed: 6819.11 samples/sec#011loss=13.811760\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] processed a total of 1957 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067527.8624206, \"EndTime\": 1681067528.463278, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 600.4655361175537, \"count\": 1, \"min\": 600.4655361175537, \"max\": 600.4655361175537}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3258.3008802063528 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #progress_metric: host=algo-1, completed 81.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=80, train loss <loss>=13.265787661075592\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[81] Batch[0] avg_epoch_loss=13.486357\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=13.486356735229492\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[81] Batch[5] avg_epoch_loss=13.171914\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=13.171914100646973\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[81] Batch [5]#011Speed: 7048.81 samples/sec#011loss=13.171914\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[81] Batch[10] avg_epoch_loss=13.297990\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=13.449280548095704\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:08 INFO 139724334417728] Epoch[81] Batch [10]#011Speed: 3001.73 samples/sec#011loss=13.449281\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] processed a total of 1879 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067528.4633944, \"EndTime\": 1681067529.0692787, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 605.3836345672607, \"count\": 1, \"min\": 605.3836345672607, \"max\": 605.3836345672607}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3103.1826882263213 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #progress_metric: host=algo-1, completed 82.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=81, train loss <loss>=13.440513801574706\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[82] Batch[0] avg_epoch_loss=13.214807\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=13.21480655670166\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[82] Batch[5] avg_epoch_loss=12.562895\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=12.562894503275553\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[82] Batch [5]#011Speed: 6117.78 samples/sec#011loss=12.562895\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[82] Batch[10] avg_epoch_loss=12.893423\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=13.290058135986328\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[82] Batch [10]#011Speed: 2905.91 samples/sec#011loss=13.290058\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] processed a total of 1912 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067529.0693643, \"EndTime\": 1681067529.675987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 606.2226295471191, \"count\": 1, \"min\": 606.2226295471191, \"max\": 606.2226295471191}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3153.340464041265 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #progress_metric: host=algo-1, completed 83.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=82, train loss <loss>=12.931686719258627\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] Epoch[83] Batch[0] avg_epoch_loss=12.833441\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:09 INFO 139724334417728] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=12.833440780639648\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch[5] avg_epoch_loss=12.998589\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=12.998588879903158\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch [5]#011Speed: 7047.60 samples/sec#011loss=12.998589\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch[10] avg_epoch_loss=13.164081\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=13.362671279907227\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch [10]#011Speed: 3697.37 samples/sec#011loss=13.362671\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch[15] avg_epoch_loss=13.550435\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=83, batch=15 train loss <loss>=14.400414085388183\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[83] Batch [15]#011Speed: 7021.39 samples/sec#011loss=14.400414\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] processed a total of 1936 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067529.676068, \"EndTime\": 1681067530.2655876, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 589.0960693359375, \"count\": 1, \"min\": 589.0960693359375, \"max\": 589.0960693359375}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3285.7141012002717 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=83, train loss <loss>=13.5504350066185\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[84] Batch[0] avg_epoch_loss=13.681295\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=13.681295394897461\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[84] Batch[5] avg_epoch_loss=13.165430\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=13.165430068969727\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[84] Batch [5]#011Speed: 7404.85 samples/sec#011loss=13.165430\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[84] Batch[10] avg_epoch_loss=13.238637\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=13.326484680175781\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] Epoch[84] Batch [10]#011Speed: 3632.73 samples/sec#011loss=13.326485\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] processed a total of 1904 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067530.26567, \"EndTime\": 1681067530.809049, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 542.9573059082031, \"count\": 1, \"min\": 542.9573059082031, \"max\": 542.9573059082031}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3505.449945877232 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:10 INFO 139724334417728] #quality_metric: host=algo-1, epoch=84, train loss <loss>=13.343681399027506\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[85] Batch[0] avg_epoch_loss=12.858388\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=12.85838794708252\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[85] Batch[5] avg_epoch_loss=13.348741\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=13.348740736643473\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[85] Batch [5]#011Speed: 6409.77 samples/sec#011loss=13.348741\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[85] Batch[10] avg_epoch_loss=13.044181\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=12.67870922088623\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[85] Batch [10]#011Speed: 2791.44 samples/sec#011loss=12.678709\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] processed a total of 1909 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067530.8091974, \"EndTime\": 1681067531.4072757, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 597.588062286377, \"count\": 1, \"min\": 597.588062286377, \"max\": 597.588062286377}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3193.8507480308995 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #progress_metric: host=algo-1, completed 86.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=85, train loss <loss>=13.0634433110555\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[86] Batch[0] avg_epoch_loss=12.976004\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=12.976003646850586\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[86] Batch[5] avg_epoch_loss=12.975326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=12.97532574335734\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[86] Batch [5]#011Speed: 7551.29 samples/sec#011loss=12.975326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[86] Batch[10] avg_epoch_loss=13.019689\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=13.07292423248291\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:11 INFO 139724334417728] Epoch[86] Batch [10]#011Speed: 3506.94 samples/sec#011loss=13.072924\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] processed a total of 1915 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067531.4073536, \"EndTime\": 1681067532.009639, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 601.8776893615723, \"count\": 1, \"min\": 601.8776893615723, \"max\": 601.8776893615723}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3181.0480149767345 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #progress_metric: host=algo-1, completed 87.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=86, train loss <loss>=13.17396977742513\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[87] Batch[0] avg_epoch_loss=13.699905\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=13.699905395507812\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[87] Batch[5] avg_epoch_loss=13.631436\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=13.631436347961426\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[87] Batch [5]#011Speed: 7416.25 samples/sec#011loss=13.631436\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[87] Batch[10] avg_epoch_loss=13.257670\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=12.809150314331054\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[87] Batch [10]#011Speed: 3580.49 samples/sec#011loss=12.809150\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] processed a total of 1887 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067532.0097172, \"EndTime\": 1681067532.6196096, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 609.2896461486816, \"count\": 1, \"min\": 609.2896461486816, \"max\": 609.2896461486816}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3096.413068338086 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=87, train loss <loss>=12.96453685760498\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[88] Batch[0] avg_epoch_loss=12.685884\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=12.685883522033691\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[88] Batch[5] avg_epoch_loss=12.655120\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=12.65511973698934\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:12 INFO 139724334417728] Epoch[88] Batch [5]#011Speed: 7211.06 samples/sec#011loss=12.655120\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[88] Batch[10] avg_epoch_loss=13.098051\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=13.629567527770996\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[88] Batch [10]#011Speed: 3434.44 samples/sec#011loss=13.629568\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[88] Batch[15] avg_epoch_loss=12.776761\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=88, batch=15 train loss <loss>=12.069925117492676\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[88] Batch [15]#011Speed: 7147.55 samples/sec#011loss=12.069925\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] processed a total of 1953 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067532.6196966, \"EndTime\": 1681067533.208979, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 588.878870010376, \"count\": 1, \"min\": 588.878870010376, \"max\": 588.878870010376}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3315.6097060648535 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #progress_metric: host=algo-1, completed 89.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=88, train loss <loss>=12.7767613530159\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch[0] avg_epoch_loss=12.861805\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=12.861804962158203\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch[5] avg_epoch_loss=13.104896\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=13.104896227518717\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch [5]#011Speed: 7368.49 samples/sec#011loss=13.104896\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch[10] avg_epoch_loss=12.982053\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=12.83464012145996\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch [10]#011Speed: 3037.89 samples/sec#011loss=12.834640\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch[15] avg_epoch_loss=13.162419\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=89, batch=15 train loss <loss>=13.559224510192871\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] Epoch[89] Batch [15]#011Speed: 7295.00 samples/sec#011loss=13.559225\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] processed a total of 1947 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067533.2090952, \"EndTime\": 1681067533.859133, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 649.6133804321289, \"count\": 1, \"min\": 649.6133804321289, \"max\": 649.6133804321289}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2996.506369077345 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:13 INFO 139724334417728] #quality_metric: host=algo-1, epoch=89, train loss <loss>=13.162418782711029\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[90] Batch[0] avg_epoch_loss=13.063366\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=13.063365936279297\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[90] Batch[5] avg_epoch_loss=12.896777\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=12.896776835123697\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[90] Batch [5]#011Speed: 7229.20 samples/sec#011loss=12.896777\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[90] Batch[10] avg_epoch_loss=12.904150\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=12.912997245788574\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[90] Batch [10]#011Speed: 3248.41 samples/sec#011loss=12.912997\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] processed a total of 1912 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067533.859237, \"EndTime\": 1681067534.4384322, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 578.6800384521484, \"count\": 1, \"min\": 578.6800384521484, \"max\": 578.6800384521484}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3303.5076368423784 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #progress_metric: host=algo-1, completed 91.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=90, train loss <loss>=12.95312328338623\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[91] Batch[0] avg_epoch_loss=13.692344\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=13.692343711853027\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[91] Batch[5] avg_epoch_loss=12.991218\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=12.991218249003092\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[91] Batch [5]#011Speed: 7585.22 samples/sec#011loss=12.991218\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[91] Batch[10] avg_epoch_loss=13.143926\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=13.32717514038086\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:14 INFO 139724334417728] Epoch[91] Batch [10]#011Speed: 2858.40 samples/sec#011loss=13.327175\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[91] Batch[15] avg_epoch_loss=12.548080\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=91, batch=15 train loss <loss>=11.237219905853271\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[91] Batch [15]#011Speed: 7233.39 samples/sec#011loss=11.237220\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] processed a total of 1946 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067534.4384968, \"EndTime\": 1681067535.0357647, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 596.7974662780762, \"count\": 1, \"min\": 596.7974662780762, \"max\": 596.7974662780762}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3259.244244592395 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=91, train loss <loss>=12.548080295324326\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[92] Batch[0] avg_epoch_loss=13.405122\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=13.405121803283691\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[92] Batch[5] avg_epoch_loss=12.953592\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=12.953592459360758\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[92] Batch [5]#011Speed: 7379.85 samples/sec#011loss=12.953592\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[92] Batch[10] avg_epoch_loss=13.009357\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=13.076274490356445\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[92] Batch [10]#011Speed: 2917.18 samples/sec#011loss=13.076274\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] processed a total of 1901 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067535.0359993, \"EndTime\": 1681067535.6909828, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 654.5727252960205, \"count\": 1, \"min\": 654.5727252960205, \"max\": 654.5727252960205}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2903.606051513024 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #progress_metric: host=algo-1, completed 93.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=92, train loss <loss>=13.152335039774577\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] Epoch[93] Batch[0] avg_epoch_loss=13.533698\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:15 INFO 139724334417728] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=13.533698081970215\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[93] Batch[5] avg_epoch_loss=13.324423\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=13.324422836303711\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[93] Batch [5]#011Speed: 7552.97 samples/sec#011loss=13.324423\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[93] Batch[10] avg_epoch_loss=13.077915\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=12.782106590270995\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[93] Batch [10]#011Speed: 2987.81 samples/sec#011loss=12.782107\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] processed a total of 1858 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067535.6910622, \"EndTime\": 1681067536.2977, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 606.1606407165527, \"count\": 1, \"min\": 606.1606407165527, \"max\": 606.1606407165527}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3064.569683909176 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #progress_metric: host=algo-1, completed 94.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=93, train loss <loss>=12.67973772684733\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch[0] avg_epoch_loss=13.532967\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=13.532966613769531\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch[5] avg_epoch_loss=13.292158\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=13.292157649993896\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch [5]#011Speed: 7623.41 samples/sec#011loss=13.292158\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch[10] avg_epoch_loss=13.191752\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=13.071264457702636\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch [10]#011Speed: 2749.50 samples/sec#011loss=13.071264\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch[15] avg_epoch_loss=13.522434\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=94, batch=15 train loss <loss>=14.249933624267578\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] Epoch[94] Batch [15]#011Speed: 7373.95 samples/sec#011loss=14.249934\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] processed a total of 1986 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067536.2977867, \"EndTime\": 1681067536.9546776, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 656.522274017334, \"count\": 1, \"min\": 656.522274017334, \"max\": 656.522274017334}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3024.493551714635 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:16 INFO 139724334417728] #quality_metric: host=algo-1, epoch=94, train loss <loss>=13.522433519363403\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch[0] avg_epoch_loss=12.503447\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=12.503446578979492\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch[5] avg_epoch_loss=13.198051\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=13.198051293691\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch [5]#011Speed: 7524.85 samples/sec#011loss=13.198051\u001b[0m\n",
      "\n",
      "2023-04-09 19:12:29 Uploading - Uploading generated training model\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch[10] avg_epoch_loss=13.229448\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=13.26712417602539\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch [10]#011Speed: 2846.04 samples/sec#011loss=13.267124\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch[15] avg_epoch_loss=13.230899\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=95, batch=15 train loss <loss>=13.234091186523438\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[95] Batch [15]#011Speed: 7400.44 samples/sec#011loss=13.234091\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] processed a total of 1952 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067536.954759, \"EndTime\": 1681067537.614541, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 659.3523025512695, \"count\": 1, \"min\": 659.3523025512695, \"max\": 659.3523025512695}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2959.985498124178 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #progress_metric: host=algo-1, completed 96.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=95, train loss <loss>=13.230899035930634\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[96] Batch[0] avg_epoch_loss=13.695400\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=13.69540023803711\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[96] Batch[5] avg_epoch_loss=12.896132\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=12.89613151550293\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:17 INFO 139724334417728] Epoch[96] Batch [5]#011Speed: 6740.66 samples/sec#011loss=12.896132\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[96] Batch[10] avg_epoch_loss=12.932596\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=12.976352882385253\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[96] Batch [10]#011Speed: 3411.87 samples/sec#011loss=12.976353\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[96] Batch[15] avg_epoch_loss=13.457573\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=96, batch=15 train loss <loss>=14.612521934509278\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[96] Batch [15]#011Speed: 6350.60 samples/sec#011loss=14.612522\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] processed a total of 1926 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067537.6146166, \"EndTime\": 1681067538.261892, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 646.914005279541, \"count\": 1, \"min\": 646.914005279541, \"max\": 646.914005279541}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=2976.666553911766 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #progress_metric: host=algo-1, completed 97.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=96, train loss <loss>=13.45757269859314\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch[0] avg_epoch_loss=13.741114\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=13.741113662719727\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch[5] avg_epoch_loss=13.185146\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=13.18514617284139\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch [5]#011Speed: 6816.80 samples/sec#011loss=13.185146\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch[10] avg_epoch_loss=12.981622\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=12.737393951416015\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch [10]#011Speed: 3564.43 samples/sec#011loss=12.737394\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch[15] avg_epoch_loss=13.025840\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=97, batch=15 train loss <loss>=13.123119735717774\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] Epoch[97] Batch [15]#011Speed: 5714.65 samples/sec#011loss=13.123120\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] processed a total of 1975 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067538.261975, \"EndTime\": 1681067538.9040265, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 641.5772438049316, \"count\": 1, \"min\": 641.5772438049316, \"max\": 641.5772438049316}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3077.733465601094 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #progress_metric: host=algo-1, completed 98.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:18 INFO 139724334417728] #quality_metric: host=algo-1, epoch=97, train loss <loss>=13.02584034204483\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[98] Batch[0] avg_epoch_loss=12.631281\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=12.631280899047852\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[98] Batch[5] avg_epoch_loss=13.273490\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=13.273489634195963\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[98] Batch [5]#011Speed: 6829.52 samples/sec#011loss=13.273490\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[98] Batch[10] avg_epoch_loss=13.035204\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=12.749262237548828\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[98] Batch [10]#011Speed: 3447.63 samples/sec#011loss=12.749262\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] processed a total of 1911 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067538.9041152, \"EndTime\": 1681067539.4761908, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 571.6028213500977, \"count\": 1, \"min\": 571.6028213500977, \"max\": 571.6028213500977}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3342.5445810786464 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #progress_metric: host=algo-1, completed 99.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=98, train loss <loss>=13.111502202351888\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[99] Batch[0] avg_epoch_loss=12.732788\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=12.7327880859375\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[99] Batch[5] avg_epoch_loss=13.032613\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=13.032613277435303\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[99] Batch [5]#011Speed: 7559.33 samples/sec#011loss=13.032613\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[99] Batch[10] avg_epoch_loss=12.928074\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=12.802625846862792\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:19 INFO 139724334417728] Epoch[99] Batch [10]#011Speed: 2993.74 samples/sec#011loss=12.802626\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] processed a total of 1892 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067539.4762678, \"EndTime\": 1681067540.0611496, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 584.2416286468506, \"count\": 1, \"min\": 584.2416286468506, \"max\": 584.2416286468506}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #throughput_metric: host=algo-1, train throughput=3237.648908118782 records/second\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #quality_metric: host=algo-1, epoch=99, train loss <loss>=12.94586353302002\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Final loss: 12.94586353302002 (occurred at epoch 99)\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #quality_metric: host=algo-1, train final_loss <loss>=12.94586353302002\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 WARNING 139724334417728] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.0612411, \"EndTime\": 1681067540.0941129, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 31.798124313354492, \"count\": 1, \"min\": 31.798124313354492, \"max\": 31.798124313354492}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.0942338, \"EndTime\": 1681067540.1166654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 54.41546440124512, \"count\": 1, \"min\": 54.41546440124512, \"max\": 54.41546440124512}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.1167488, \"EndTime\": 1681067540.1203995, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.604412078857422, \"count\": 1, \"min\": 3.604412078857422, \"max\": 3.604412078857422}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #memory_usage::<batchbuffer> = 0.25390625 mb\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.1204665, \"EndTime\": 1681067540.1220467, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.036716461181640625, \"count\": 1, \"min\": 0.036716461181640625, \"max\": 0.036716461181640625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.122143, \"EndTime\": 1681067540.7446084, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 622.6029396057129, \"count\": 1, \"min\": 622.6029396057129, \"max\": 622.6029396057129}}}\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, RMSE): 1772517524.8042376\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, mean_absolute_QuantileLoss): 27890541111.04471\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, mean_wQuantileLoss): 0.9979177074904345\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.1]): 0.20331071214542862\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.2]): 0.4026403634936539\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.3]): 0.6015314683774318\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.4]): 0.8007102948357762\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.5]): 0.9998499023950672\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.6]): 1.1987986750674158\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.7]): 1.3970498537212201\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.8]): 1.5933797185478416\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #test_score (algo-1, wQuantileLoss[0.9]): 1.783988378830075\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #quality_metric: host=algo-1, test RMSE <loss>=1772517524.8042376\u001b[0m\n",
      "\u001b[34m[04/09/2023 19:12:20 INFO 139724334417728] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.9979177074904345\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1681067540.744681, \"EndTime\": 1681067540.751075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 5.856990814208984, \"count\": 1, \"min\": 5.856990814208984, \"max\": 5.856990814208984}, \"totaltime\": {\"sum\": 62479.313135147095, \"count\": 1, \"min\": 62479.313135147095, \"max\": 62479.313135147095}}}\u001b[0m\n",
      "\n",
      "2023-04-09 19:12:40 Completed - Training job completed\n",
      "Training seconds: 203\n",
      "Billable seconds: 203\n",
      "CPU times: user 906 ms, sys: 105 ms, total: 1.01 s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train\".format(s3_data_path), \"test\": \"{}/test\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3c712-3c85-4761-9007-0f39aa4b5b3f",
   "metadata": {},
   "source": [
    "## Creating Endpoint to make predictions on newly fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe432457-3202-4992-ab37-0fdbe9179ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    image_uri=image_name,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3bf922d-5131-4eba-b617-46b29f3a653a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=b'{\"instances\": [{\"start\": \"2021-10-01T00:00:00\", \"target\": [487.0, 1354033.0, 768745602.4769465, 81.54286336132316, 3866649606.462566, 6618.0, 15584.9]}, {\"start\": \"2021-11-01T00:00:00\", \"target\": [472.0, 1444907.0, 772187761.0169934, 81.41902126355457, 4027304584.965656, 5586.0, 15543.5]},{\"start\": \"2021-12-01T00:00:00\", \"target\": [485.0, 1395610.0, 773618808.1795698, 82.06188448788464, 3984239441.91169, 5147.0, 15483.6]}]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68a26bee-da56-4004-a784-64c6f0bc2ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [{'mean': [-3852.9028320312, -4765.8583984375, -11023.3310546875, -3289.630859375, 1570.6770019531]}, {'mean': [-3667.1015625, -4535.9848632812, -10483.7138671875, -3124.5859375, 1494.2780761719]}, {'mean': [-3580.4362792969, -4428.7143554688, -10241.986328125, -3052.8334960938, 1459.1770019531]}]\n"
     ]
    }
   ],
   "source": [
    "result = json.loads(response['Body'].read().decode())\n",
    "\n",
    "predicted_values = result['predictions']\n",
    "print('Predicted values:', predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf6c11-f82d-474e-a0e8-549b60a9b15e",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ad46828-1c6c-499d-9123-de52a11418f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf80db3-b6f4-44c1-8d07-1bedc5148b2d",
   "metadata": {},
   "source": [
    "## Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b40fd88f-a041-42c1-a144-6643d9cfc0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74ab3b-3aeb-4749-b0f2-a96c8b9adc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7c43a-c5e7-42d3-a413-fae7fdbdb8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
